"""
Performance attribution module for QuantumAlpha Analytics Service.
Provides detailed performance attribution and decomposition analysis.
"""

import os
import logging
from typing import Dict, Any, List, Optional, Tuple, Union
from datetime import datetime, timedelta
import numpy as np
import pandas as pd
from dataclasses import dataclass
from enum import Enum
import json

# Add parent directory to path to import common modules
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from common import setup_logger, ServiceError, ValidationError, NotFoundError

# Configure logging
logger = setup_logger("performance_attribution", logging.INFO)


class AttributionMethod(Enum):
    """Performance attribution methods"""

    BRINSON_HOOD_BEEBOWER = "brinson_hood_beebower"
    BRINSON_FACHLER = "brinson_fachler"
    GEOMETRIC_ATTRIBUTION = "geometric_attribution"
    ARITHMETIC_ATTRIBUTION = "arithmetic_attribution"
    FACTOR_BASED = "factor_based"
    RISK_ADJUSTED = "risk_adjusted"


class AttributionLevel(Enum):
    """Attribution analysis levels"""

    SECURITY = "security"
    SECTOR = "sector"
    ASSET_CLASS = "asset_class"
    GEOGRAPHY = "geography"
    CURRENCY = "currency"
    FACTOR = "factor"


@dataclass
class AttributionResult:
    """Performance attribution result"""

    total_return: float
    benchmark_return: float
    active_return: float
    allocation_effect: float
    selection_effect: float
    interaction_effect: float
    currency_effect: Optional[float] = None
    timing_effect: Optional[float] = None
    detailed_breakdown: Optional[Dict[str, Any]] = None


@dataclass
class SecurityAttribution:
    """Security-level attribution"""

    security_id: str
    security_name: str
    weight_portfolio: float
    weight_benchmark: float
    return_portfolio: float
    return_benchmark: float
    allocation_contribution: float
    selection_contribution: float
    total_contribution: float


class PerformanceAttributionEngine:
    """Comprehensive performance attribution engine"""

    def __init__(self, config_manager, db_manager):
        """Initialize performance attribution engine

        Args:
            config_manager: Configuration manager
            db_manager: Database manager
        """
        self.config_manager = config_manager
        self.db_manager = db_manager

        # Attribution settings
        self.default_method = AttributionMethod.BRINSON_HOOD_BEEBOWER
        self.default_frequency = "daily"

        # Risk-free rate for calculations
        self.risk_free_rate = 0.02  # 2% annual

        # Factor models
        self.factor_models = {}
        self._initialize_factor_models()

        logger.info("Performance attribution engine initialized")

    def calculate_attribution(
        self,
        portfolio_returns: pd.DataFrame,
        benchmark_returns: pd.DataFrame,
        portfolio_weights: pd.DataFrame,
        benchmark_weights: pd.DataFrame,
        method: str = "brinson_hood_beebower",
        level: str = "sector",
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
    ) -> Dict[str, Any]:
        """Calculate performance attribution

        Args:
            portfolio_returns: Portfolio returns data
            benchmark_returns: Benchmark returns data
            portfolio_weights: Portfolio weights data
            benchmark_weights: Benchmark weights data
            method: Attribution method
            level: Attribution level
            start_date: Analysis start date
            end_date: Analysis end date

        Returns:
            Attribution analysis results
        """
        try:
            logger.info(
                f"Calculating attribution using {method} method at {level} level"
            )

            # Validate inputs
            self._validate_attribution_inputs(
                portfolio_returns,
                benchmark_returns,
                portfolio_weights,
                benchmark_weights,
            )

            # Filter by date range if specified
            if start_date or end_date:
                (
                    portfolio_returns,
                    benchmark_returns,
                    portfolio_weights,
                    benchmark_weights,
                ) = self._filter_by_date_range(
                    portfolio_returns,
                    benchmark_returns,
                    portfolio_weights,
                    benchmark_weights,
                    start_date,
                    end_date,
                )

            # Calculate attribution based on method
            if method == AttributionMethod.BRINSON_HOOD_BEEBOWER.value:
                result = self._calculate_brinson_hood_beebower(
                    portfolio_returns,
                    benchmark_returns,
                    portfolio_weights,
                    benchmark_weights,
                    level,
                )
            elif method == AttributionMethod.BRINSON_FACHLER.value:
                result = self._calculate_brinson_fachler(
                    portfolio_returns,
                    benchmark_returns,
                    portfolio_weights,
                    benchmark_weights,
                    level,
                )
            elif method == AttributionMethod.GEOMETRIC_ATTRIBUTION.value:
                result = self._calculate_geometric_attribution(
                    portfolio_returns,
                    benchmark_returns,
                    portfolio_weights,
                    benchmark_weights,
                    level,
                )
            elif method == AttributionMethod.FACTOR_BASED.value:
                result = self._calculate_factor_based_attribution(
                    portfolio_returns,
                    benchmark_returns,
                    portfolio_weights,
                    benchmark_weights,
                    level,
                )
            else:
                result = self._calculate_arithmetic_attribution(
                    portfolio_returns,
                    benchmark_returns,
                    portfolio_weights,
                    benchmark_weights,
                    level,
                )

            # Add metadata
            result["method"] = method
            result["level"] = level
            result["period"] = {
                "start": (
                    portfolio_returns.index[0].isoformat()
                    if len(portfolio_returns) > 0
                    else None
                ),
                "end": (
                    portfolio_returns.index[-1].isoformat()
                    if len(portfolio_returns) > 0
                    else None
                ),
            }
            result["calculated_at"] = datetime.utcnow().isoformat()

            return result

        except Exception as e:
            logger.error(f"Error calculating attribution: {e}")
            raise ServiceError(f"Error calculating attribution: {str(e)}")

    def calculate_multi_period_attribution(
        self,
        portfolio_returns: pd.DataFrame,
        benchmark_returns: pd.DataFrame,
        portfolio_weights: pd.DataFrame,
        benchmark_weights: pd.DataFrame,
        periods: List[Tuple[datetime, datetime]],
        method: str = "brinson_hood_beebower",
        level: str = "sector",
    ) -> Dict[str, Any]:
        """Calculate attribution across multiple periods

        Args:
            portfolio_returns: Portfolio returns data
            benchmark_returns: Benchmark returns data
            portfolio_weights: Portfolio weights data
            benchmark_weights: Benchmark weights data
            periods: List of (start_date, end_date) tuples
            method: Attribution method
            level: Attribution level

        Returns:
            Multi-period attribution results
        """
        try:
            logger.info(
                f"Calculating multi-period attribution for {len(periods)} periods"
            )

            period_results = []

            for i, (start_date, end_date) in enumerate(periods):
                try:
                    period_result = self.calculate_attribution(
                        portfolio_returns,
                        benchmark_returns,
                        portfolio_weights,
                        benchmark_weights,
                        method,
                        level,
                        start_date,
                        end_date,
                    )
                    period_result["period_index"] = i
                    period_result["period_start"] = start_date.isoformat()
                    period_result["period_end"] = end_date.isoformat()
                    period_results.append(period_result)

                except Exception as e:
                    logger.warning(f"Error calculating attribution for period {i}: {e}")
                    period_results.append(
                        {
                            "period_index": i,
                            "period_start": start_date.isoformat(),
                            "period_end": end_date.isoformat(),
                            "error": str(e),
                        }
                    )

            # Calculate aggregate statistics
            valid_results = [r for r in period_results if "error" not in r]

            if valid_results:
                aggregate_stats = self._calculate_aggregate_attribution_stats(
                    valid_results
                )
            else:
                aggregate_stats = {}

            return {
                "period_results": period_results,
                "aggregate_statistics": aggregate_stats,
                "method": method,
                "level": level,
                "total_periods": len(periods),
                "successful_periods": len(valid_results),
                "calculated_at": datetime.utcnow().isoformat(),
            }

        except Exception as e:
            logger.error(f"Error calculating multi-period attribution: {e}")
            raise ServiceError(f"Error calculating multi-period attribution: {str(e)}")

    def calculate_security_level_attribution(
        self,
        portfolio_data: Dict[str, Any],
        benchmark_data: Dict[str, Any],
        returns_data: Dict[str, pd.DataFrame],
        period_start: datetime,
        period_end: datetime,
    ) -> Dict[str, Any]:
        """Calculate security-level performance attribution

        Args:
            portfolio_data: Portfolio holdings data
            benchmark_data: Benchmark holdings data
            returns_data: Security returns data
            period_start: Analysis start date
            period_end: Analysis end date

        Returns:
            Security-level attribution results
        """
        try:
            logger.info("Calculating security-level attribution")

            security_attributions = []
            total_allocation_effect = 0
            total_selection_effect = 0

            # Get all securities in portfolio and benchmark
            portfolio_securities = set(portfolio_data.get("holdings", {}).keys())
            benchmark_securities = set(benchmark_data.get("holdings", {}).keys())
            all_securities = portfolio_securities.union(benchmark_securities)

            for security_id in all_securities:
                try:
                    # Get weights
                    portfolio_weight = (
                        portfolio_data.get("holdings", {})
                        .get(security_id, {})
                        .get("weight", 0)
                    )
                    benchmark_weight = (
                        benchmark_data.get("holdings", {})
                        .get(security_id, {})
                        .get("weight", 0)
                    )

                    # Get returns
                    if security_id in returns_data:
                        security_returns = returns_data[security_id]
                        period_returns = security_returns.loc[period_start:period_end]

                        if len(period_returns) > 0:
                            portfolio_return = period_returns.get("portfolio_return", 0)
                            benchmark_return = period_returns.get("benchmark_return", 0)
                        else:
                            portfolio_return = 0
                            benchmark_return = 0
                    else:
                        portfolio_return = 0
                        benchmark_return = 0

                    # Calculate attribution effects
                    allocation_contribution = (
                        portfolio_weight - benchmark_weight
                    ) * benchmark_return
                    selection_contribution = benchmark_weight * (
                        portfolio_return - benchmark_return
                    )
                    total_contribution = (
                        allocation_contribution + selection_contribution
                    )

                    # Create security attribution
                    security_attribution = SecurityAttribution(
                        security_id=security_id,
                        security_name=portfolio_data.get("holdings", {})
                        .get(security_id, {})
                        .get("name", security_id),
                        weight_portfolio=portfolio_weight,
                        weight_benchmark=benchmark_weight,
                        return_portfolio=portfolio_return,
                        return_benchmark=benchmark_return,
                        allocation_contribution=allocation_contribution,
                        selection_contribution=selection_contribution,
                        total_contribution=total_contribution,
                    )

                    security_attributions.append(security_attribution)
                    total_allocation_effect += allocation_contribution
                    total_selection_effect += selection_contribution

                except Exception as e:
                    logger.warning(
                        f"Error calculating attribution for security {security_id}: {e}"
                    )

            # Sort by total contribution
            security_attributions.sort(
                key=lambda x: abs(x.total_contribution), reverse=True
            )

            # Calculate portfolio and benchmark returns
            portfolio_return = sum(
                attr.weight_portfolio * attr.return_portfolio
                for attr in security_attributions
            )
            benchmark_return = sum(
                attr.weight_benchmark * attr.return_benchmark
                for attr in security_attributions
            )

            return {
                "total_return": portfolio_return,
                "benchmark_return": benchmark_return,
                "active_return": portfolio_return - benchmark_return,
                "allocation_effect": total_allocation_effect,
                "selection_effect": total_selection_effect,
                "interaction_effect": 0,  # Not calculated at security level
                "security_attributions": [
                    {
                        "security_id": attr.security_id,
                        "security_name": attr.security_name,
                        "weight_portfolio": attr.weight_portfolio,
                        "weight_benchmark": attr.weight_benchmark,
                        "return_portfolio": attr.return_portfolio,
                        "return_benchmark": attr.return_benchmark,
                        "allocation_contribution": attr.allocation_contribution,
                        "selection_contribution": attr.selection_contribution,
                        "total_contribution": attr.total_contribution,
                    }
                    for attr in security_attributions
                ],
                "top_contributors": [
                    {
                        "security_id": attr.security_id,
                        "security_name": attr.security_name,
                        "contribution": attr.total_contribution,
                    }
                    for attr in security_attributions[:10]  # Top 10 contributors
                ],
                "top_detractors": [
                    {
                        "security_id": attr.security_id,
                        "security_name": attr.security_name,
                        "contribution": attr.total_contribution,
                    }
                    for attr in sorted(
                        security_attributions, key=lambda x: x.total_contribution
                    )[
                        :10
                    ]  # Top 10 detractors
                ],
            }

        except Exception as e:
            logger.error(f"Error calculating security-level attribution: {e}")
            raise ServiceError(
                f"Error calculating security-level attribution: {str(e)}"
            )

    def _calculate_brinson_hood_beebower(
        self,
        portfolio_returns: pd.DataFrame,
        benchmark_returns: pd.DataFrame,
        portfolio_weights: pd.DataFrame,
        benchmark_weights: pd.DataFrame,
        level: str,
    ) -> Dict[str, Any]:
        """Calculate Brinson-Hood-Beebower attribution

        Args:
            portfolio_returns: Portfolio returns
            benchmark_returns: Benchmark returns
            portfolio_weights: Portfolio weights
            benchmark_weights: Benchmark weights
            level: Attribution level

        Returns:
            BHB attribution results
        """
        try:
            # Align data
            common_index = portfolio_returns.index.intersection(benchmark_returns.index)
            common_columns = portfolio_returns.columns.intersection(
                benchmark_returns.columns
            )

            if len(common_index) == 0 or len(common_columns) == 0:
                raise ValidationError("No common data between portfolio and benchmark")

            # Get aligned data
            port_ret = portfolio_returns.loc[common_index, common_columns]
            bench_ret = benchmark_returns.loc[common_index, common_columns]
            port_wgt = (
                portfolio_weights.loc[common_index, common_columns]
                if len(portfolio_weights) > 0
                else pd.DataFrame(0, index=common_index, columns=common_columns)
            )
            bench_wgt = (
                benchmark_weights.loc[common_index, common_columns]
                if len(benchmark_weights) > 0
                else pd.DataFrame(0, index=common_index, columns=common_columns)
            )

            # Calculate period returns (geometric)
            port_total_return = (1 + port_ret).prod() - 1
            bench_total_return = (1 + bench_ret).prod() - 1

            # Calculate weighted returns
            portfolio_return = (port_wgt.iloc[-1] * port_total_return).sum()
            benchmark_return = (bench_wgt.iloc[-1] * bench_total_return).sum()

            # Calculate attribution effects
            allocation_effect = (
                (port_wgt.iloc[-1] - bench_wgt.iloc[-1]) * bench_total_return
            ).sum()
            selection_effect = (
                bench_wgt.iloc[-1] * (port_total_return - bench_total_return)
            ).sum()
            interaction_effect = (
                (port_wgt.iloc[-1] - bench_wgt.iloc[-1])
                * (port_total_return - bench_total_return)
            ).sum()

            # Detailed breakdown by sector/level
            detailed_breakdown = {}
            for col in common_columns:
                detailed_breakdown[col] = {
                    "portfolio_weight": float(port_wgt.iloc[-1][col]),
                    "benchmark_weight": float(bench_wgt.iloc[-1][col]),
                    "portfolio_return": float(port_total_return[col]),
                    "benchmark_return": float(bench_total_return[col]),
                    "allocation_effect": float(
                        (port_wgt.iloc[-1][col] - bench_wgt.iloc[-1][col])
                        * bench_total_return[col]
                    ),
                    "selection_effect": float(
                        bench_wgt.iloc[-1][col]
                        * (port_total_return[col] - bench_total_return[col])
                    ),
                    "interaction_effect": float(
                        (port_wgt.iloc[-1][col] - bench_wgt.iloc[-1][col])
                        * (port_total_return[col] - bench_total_return[col])
                    ),
                }

            return AttributionResult(
                total_return=float(portfolio_return),
                benchmark_return=float(benchmark_return),
                active_return=float(portfolio_return - benchmark_return),
                allocation_effect=float(allocation_effect),
                selection_effect=float(selection_effect),
                interaction_effect=float(interaction_effect),
                detailed_breakdown=detailed_breakdown,
            ).__dict__

        except Exception as e:
            logger.error(f"Error in BHB attribution: {e}")
            raise

    def _calculate_brinson_fachler(
        self,
        portfolio_returns: pd.DataFrame,
        benchmark_returns: pd.DataFrame,
        portfolio_weights: pd.DataFrame,
        benchmark_weights: pd.DataFrame,
        level: str,
    ) -> Dict[str, Any]:
        """Calculate Brinson-Fachler attribution (geometric)

        Args:
            portfolio_returns: Portfolio returns
            benchmark_returns: Benchmark returns
            portfolio_weights: Portfolio weights
            benchmark_weights: Benchmark weights
            level: Attribution level

        Returns:
            Brinson-Fachler attribution results
        """
        try:
            # Similar to BHB but with geometric linking
            bhb_result = self._calculate_brinson_hood_beebower(
                portfolio_returns,
                benchmark_returns,
                portfolio_weights,
                benchmark_weights,
                level,
            )

            # Adjust for geometric effects
            total_active = bhb_result["active_return"]
            allocation = bhb_result["allocation_effect"]
            selection = bhb_result["selection_effect"]
            interaction = bhb_result["interaction_effect"]

            # Geometric adjustment
            geometric_adjustment = total_active - (allocation + selection + interaction)

            return AttributionResult(
                total_return=bhb_result["total_return"],
                benchmark_return=bhb_result["benchmark_return"],
                active_return=bhb_result["active_return"],
                allocation_effect=allocation,
                selection_effect=selection,
                interaction_effect=interaction + geometric_adjustment,
                detailed_breakdown=bhb_result["detailed_breakdown"],
            ).__dict__

        except Exception as e:
            logger.error(f"Error in Brinson-Fachler attribution: {e}")
            raise

    def _calculate_geometric_attribution(
        self,
        portfolio_returns: pd.DataFrame,
        benchmark_returns: pd.DataFrame,
        portfolio_weights: pd.DataFrame,
        benchmark_weights: pd.DataFrame,
        level: str,
    ) -> Dict[str, Any]:
        """Calculate geometric attribution

        Args:
            portfolio_returns: Portfolio returns
            benchmark_returns: Benchmark returns
            portfolio_weights: Portfolio weights
            benchmark_weights: Benchmark weights
            level: Attribution level

        Returns:
            Geometric attribution results
        """
        try:
            # Calculate cumulative returns
            port_cumret = (1 + portfolio_returns).cumprod()
            bench_cumret = (1 + benchmark_returns).cumprod()

            # Calculate geometric attribution using log returns
            log_port_ret = np.log(1 + portfolio_returns)
            log_bench_ret = np.log(1 + benchmark_returns)

            # Use BHB method on log returns
            bhb_result = self._calculate_brinson_hood_beebower(
                log_port_ret, log_bench_ret, portfolio_weights, benchmark_weights, level
            )

            # Convert back to arithmetic returns
            total_return = np.exp(bhb_result["total_return"]) - 1
            benchmark_return = np.exp(bhb_result["benchmark_return"]) - 1

            return AttributionResult(
                total_return=float(total_return),
                benchmark_return=float(benchmark_return),
                active_return=float(total_return - benchmark_return),
                allocation_effect=bhb_result["allocation_effect"],
                selection_effect=bhb_result["selection_effect"],
                interaction_effect=bhb_result["interaction_effect"],
                detailed_breakdown=bhb_result["detailed_breakdown"],
            ).__dict__

        except Exception as e:
            logger.error(f"Error in geometric attribution: {e}")
            raise

    def _calculate_factor_based_attribution(
        self,
        portfolio_returns: pd.DataFrame,
        benchmark_returns: pd.DataFrame,
        portfolio_weights: pd.DataFrame,
        benchmark_weights: pd.DataFrame,
        level: str,
    ) -> Dict[str, Any]:
        """Calculate factor-based attribution

        Args:
            portfolio_returns: Portfolio returns
            benchmark_returns: Benchmark returns
            portfolio_weights: Portfolio weights
            benchmark_weights: Benchmark weights
            level: Attribution level

        Returns:
            Factor-based attribution results
        """
        try:
            # Use a simple factor model for demonstration
            # In practice, this would use sophisticated factor models like Fama-French, Barra, etc.

            # Calculate basic factor exposures
            market_factor = portfolio_returns.mean(axis=1)  # Market factor proxy

            # Calculate factor loadings (simplified)
            factor_loadings = {}
            factor_returns = {}

            for col in portfolio_returns.columns:
                # Simple regression against market factor
                y = portfolio_returns[col].dropna()
                x = market_factor.loc[y.index]

                if len(y) > 1 and len(x) > 1:
                    # Calculate beta (factor loading)
                    covariance = np.cov(x, y)[0, 1]
                    variance = np.var(x)
                    beta = covariance / variance if variance > 0 else 0

                    # Calculate alpha (specific return)
                    alpha = np.mean(y) - beta * np.mean(x)

                    factor_loadings[col] = {"market_beta": beta, "alpha": alpha}
                    factor_returns[col] = {
                        "market_return": np.mean(x),
                        "specific_return": alpha,
                    }

            # Calculate factor attribution
            portfolio_factor_exposure = sum(
                portfolio_weights.iloc[-1].get(col, 0)
                * factor_loadings.get(col, {}).get("market_beta", 0)
                for col in portfolio_returns.columns
            )

            benchmark_factor_exposure = sum(
                benchmark_weights.iloc[-1].get(col, 0)
                * factor_loadings.get(col, {}).get("market_beta", 0)
                for col in benchmark_returns.columns
            )

            market_return = market_factor.mean()
            factor_allocation = (
                portfolio_factor_exposure - benchmark_factor_exposure
            ) * market_return

            # Calculate specific return attribution
            specific_selection = sum(
                portfolio_weights.iloc[-1].get(col, 0)
                * factor_loadings.get(col, {}).get("alpha", 0)
                for col in portfolio_returns.columns
            )

            # Calculate total returns
            portfolio_return = (
                portfolio_weights.iloc[-1] * portfolio_returns.mean()
            ).sum()
            benchmark_return = (
                benchmark_weights.iloc[-1] * benchmark_returns.mean()
            ).sum()

            return AttributionResult(
                total_return=float(portfolio_return),
                benchmark_return=float(benchmark_return),
                active_return=float(portfolio_return - benchmark_return),
                allocation_effect=float(factor_allocation),
                selection_effect=float(specific_selection),
                interaction_effect=0,
                detailed_breakdown={
                    "factor_exposures": {
                        "portfolio_market_beta": float(portfolio_factor_exposure),
                        "benchmark_market_beta": float(benchmark_factor_exposure),
                        "active_market_beta": float(
                            portfolio_factor_exposure - benchmark_factor_exposure
                        ),
                    },
                    "factor_returns": factor_returns,
                    "factor_loadings": factor_loadings,
                },
            ).__dict__

        except Exception as e:
            logger.error(f"Error in factor-based attribution: {e}")
            raise

    def _calculate_arithmetic_attribution(
        self,
        portfolio_returns: pd.DataFrame,
        benchmark_returns: pd.DataFrame,
        portfolio_weights: pd.DataFrame,
        benchmark_weights: pd.DataFrame,
        level: str,
    ) -> Dict[str, Any]:
        """Calculate arithmetic attribution (simple)

        Args:
            portfolio_returns: Portfolio returns
            benchmark_returns: Benchmark returns
            portfolio_weights: Portfolio weights
            benchmark_weights: Benchmark weights
            level: Attribution level

        Returns:
            Arithmetic attribution results
        """
        try:
            # Simple arithmetic attribution
            portfolio_return = (
                portfolio_weights.iloc[-1] * portfolio_returns.mean()
            ).sum()
            benchmark_return = (
                benchmark_weights.iloc[-1] * benchmark_returns.mean()
            ).sum()

            # Simple allocation and selection effects
            allocation_effect = (
                (portfolio_weights.iloc[-1] - benchmark_weights.iloc[-1])
                * benchmark_returns.mean()
            ).sum()
            selection_effect = (
                benchmark_weights.iloc[-1]
                * (portfolio_returns.mean() - benchmark_returns.mean())
            ).sum()

            return AttributionResult(
                total_return=float(portfolio_return),
                benchmark_return=float(benchmark_return),
                active_return=float(portfolio_return - benchmark_return),
                allocation_effect=float(allocation_effect),
                selection_effect=float(selection_effect),
                interaction_effect=0,
                detailed_breakdown={},
            ).__dict__

        except Exception as e:
            logger.error(f"Error in arithmetic attribution: {e}")
            raise

    def _validate_attribution_inputs(
        self,
        portfolio_returns: pd.DataFrame,
        benchmark_returns: pd.DataFrame,
        portfolio_weights: pd.DataFrame,
        benchmark_weights: pd.DataFrame,
    ) -> None:
        """Validate attribution inputs"""
        if portfolio_returns.empty:
            raise ValidationError("Portfolio returns data is empty")

        if benchmark_returns.empty:
            raise ValidationError("Benchmark returns data is empty")

        # Check for common time periods
        common_dates = portfolio_returns.index.intersection(benchmark_returns.index)
        if len(common_dates) == 0:
            raise ValidationError(
                "No common dates between portfolio and benchmark returns"
            )

        # Check for common securities/sectors
        common_securities = portfolio_returns.columns.intersection(
            benchmark_returns.columns
        )
        if len(common_securities) == 0:
            raise ValidationError(
                "No common securities/sectors between portfolio and benchmark"
            )

    def _filter_by_date_range(
        self,
        portfolio_returns: pd.DataFrame,
        benchmark_returns: pd.DataFrame,
        portfolio_weights: pd.DataFrame,
        benchmark_weights: pd.DataFrame,
        start_date: Optional[datetime],
        end_date: Optional[datetime],
    ) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """Filter data by date range"""

        # Create date filter
        date_filter = pd.Series(True, index=portfolio_returns.index)

        if start_date:
            date_filter = date_filter & (portfolio_returns.index >= start_date)

        if end_date:
            date_filter = date_filter & (portfolio_returns.index <= end_date)

        # Apply filter
        filtered_port_ret = portfolio_returns.loc[date_filter]
        filtered_bench_ret = benchmark_returns.loc[
            benchmark_returns.index.isin(filtered_port_ret.index)
        ]

        # Filter weights if available
        if not portfolio_weights.empty:
            filtered_port_wgt = portfolio_weights.loc[
                portfolio_weights.index.isin(filtered_port_ret.index)
            ]
        else:
            filtered_port_wgt = portfolio_weights

        if not benchmark_weights.empty:
            filtered_bench_wgt = benchmark_weights.loc[
                benchmark_weights.index.isin(filtered_bench_ret.index)
            ]
        else:
            filtered_bench_wgt = benchmark_weights

        return (
            filtered_port_ret,
            filtered_bench_ret,
            filtered_port_wgt,
            filtered_bench_wgt,
        )

    def _calculate_aggregate_attribution_stats(
        self, period_results: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Calculate aggregate statistics across periods"""
        try:
            # Extract metrics
            total_returns = [r.get("total_return", 0) for r in period_results]
            benchmark_returns = [r.get("benchmark_return", 0) for r in period_results]
            active_returns = [r.get("active_return", 0) for r in period_results]
            allocation_effects = [r.get("allocation_effect", 0) for r in period_results]
            selection_effects = [r.get("selection_effect", 0) for r in period_results]

            # Calculate statistics
            return {
                "average_total_return": float(np.mean(total_returns)),
                "average_benchmark_return": float(np.mean(benchmark_returns)),
                "average_active_return": float(np.mean(active_returns)),
                "average_allocation_effect": float(np.mean(allocation_effects)),
                "average_selection_effect": float(np.mean(selection_effects)),
                "volatility_active_return": float(np.std(active_returns)),
                "information_ratio": (
                    float(np.mean(active_returns) / np.std(active_returns))
                    if np.std(active_returns) > 0
                    else 0
                ),
                "hit_rate": float(
                    sum(1 for ar in active_returns if ar > 0) / len(active_returns)
                ),
                "cumulative_total_return": float(
                    np.prod([1 + r for r in total_returns]) - 1
                ),
                "cumulative_benchmark_return": float(
                    np.prod([1 + r for r in benchmark_returns]) - 1
                ),
                "cumulative_active_return": float(
                    np.prod([1 + r for r in active_returns]) - 1
                ),
            }

        except Exception as e:
            logger.error(f"Error calculating aggregate stats: {e}")
            return {}

    def _initialize_factor_models(self) -> None:
        """Initialize factor models for attribution"""
        # Fama-French 3-factor model
        self.factor_models["fama_french_3"] = {
            "factors": ["market", "size", "value"],
            "description": "Fama-French 3-factor model",
        }

        # Fama-French 5-factor model
        self.factor_models["fama_french_5"] = {
            "factors": ["market", "size", "value", "profitability", "investment"],
            "description": "Fama-French 5-factor model",
        }

        # Carhart 4-factor model
        self.factor_models["carhart_4"] = {
            "factors": ["market", "size", "value", "momentum"],
            "description": "Carhart 4-factor model",
        }

        logger.info(f"Initialized {len(self.factor_models)} factor models")

    def generate_attribution_report(
        self, attribution_results: Dict[str, Any], include_charts: bool = True
    ) -> Dict[str, Any]:
        """Generate comprehensive attribution report

        Args:
            attribution_results: Attribution analysis results
            include_charts: Whether to include chart data

        Returns:
            Attribution report
        """
        try:
            # Extract key metrics
            total_return = attribution_results.get("total_return", 0)
            benchmark_return = attribution_results.get("benchmark_return", 0)
            active_return = attribution_results.get("active_return", 0)
            allocation_effect = attribution_results.get("allocation_effect", 0)
            selection_effect = attribution_results.get("selection_effect", 0)
            interaction_effect = attribution_results.get("interaction_effect", 0)

            # Create summary
            summary = {
                "performance_summary": {
                    "portfolio_return": f"{total_return:.2%}",
                    "benchmark_return": f"{benchmark_return:.2%}",
                    "active_return": f"{active_return:.2%}",
                    "outperformance": active_return > 0,
                },
                "attribution_summary": {
                    "allocation_effect": f"{allocation_effect:.2%}",
                    "selection_effect": f"{selection_effect:.2%}",
                    "interaction_effect": f"{interaction_effect:.2%}",
                    "total_effect": f"{allocation_effect + selection_effect + interaction_effect:.2%}",
                },
            }

            # Detailed breakdown
            detailed_breakdown = attribution_results.get("detailed_breakdown", {})

            # Top contributors and detractors
            if detailed_breakdown:
                contributions = []
                for sector, data in detailed_breakdown.items():
                    total_contribution = data.get("allocation_effect", 0) + data.get(
                        "selection_effect", 0
                    )
                    contributions.append(
                        {
                            "sector": sector,
                            "total_contribution": total_contribution,
                            "allocation_effect": data.get("allocation_effect", 0),
                            "selection_effect": data.get("selection_effect", 0),
                        }
                    )

                contributions.sort(key=lambda x: x["total_contribution"], reverse=True)

                top_contributors = contributions[:5]
                top_detractors = contributions[-5:]
            else:
                top_contributors = []
                top_detractors = []

            # Chart data
            chart_data = {}
            if include_charts:
                chart_data = {
                    "attribution_waterfall": {
                        "categories": [
                            "Benchmark",
                            "Allocation",
                            "Selection",
                            "Interaction",
                            "Portfolio",
                        ],
                        "values": [
                            benchmark_return,
                            allocation_effect,
                            selection_effect,
                            interaction_effect,
                            total_return,
                        ],
                    },
                    "sector_contribution": {
                        "sectors": [item["sector"] for item in contributions],
                        "contributions": [
                            item["total_contribution"] for item in contributions
                        ],
                    },
                }

            return {
                "summary": summary,
                "detailed_breakdown": detailed_breakdown,
                "top_contributors": top_contributors,
                "top_detractors": top_detractors,
                "chart_data": chart_data,
                "methodology": attribution_results.get("method", "unknown"),
                "analysis_level": attribution_results.get("level", "unknown"),
                "period": attribution_results.get("period", {}),
                "generated_at": datetime.utcnow().isoformat(),
            }

        except Exception as e:
            logger.error(f"Error generating attribution report: {e}")
            raise ServiceError(f"Error generating attribution report: {str(e)}")


class RiskAdjustedAttribution:
    """Risk-adjusted performance attribution"""

    def __init__(self, attribution_engine: PerformanceAttributionEngine):
        """Initialize risk-adjusted attribution

        Args:
            attribution_engine: Performance attribution engine
        """
        self.attribution_engine = attribution_engine

    def calculate_risk_adjusted_attribution(
        self,
        portfolio_returns: pd.DataFrame,
        benchmark_returns: pd.DataFrame,
        portfolio_weights: pd.DataFrame,
        benchmark_weights: pd.DataFrame,
        risk_factors: pd.DataFrame,
        method: str = "sharpe_ratio",
    ) -> Dict[str, Any]:
        """Calculate risk-adjusted attribution

        Args:
            portfolio_returns: Portfolio returns
            benchmark_returns: Benchmark returns
            portfolio_weights: Portfolio weights
            benchmark_weights: Benchmark weights
            risk_factors: Risk factor data
            method: Risk adjustment method

        Returns:
            Risk-adjusted attribution results
        """
        try:
            # Calculate standard attribution first
            standard_attribution = self.attribution_engine.calculate_attribution(
                portfolio_returns,
                benchmark_returns,
                portfolio_weights,
                benchmark_weights,
            )

            # Calculate risk metrics
            portfolio_vol = portfolio_returns.std().mean() * np.sqrt(252)  # Annualized
            benchmark_vol = benchmark_returns.std().mean() * np.sqrt(252)

            # Risk-adjusted returns
            risk_free_rate = self.attribution_engine.risk_free_rate

            portfolio_sharpe = (
                (standard_attribution["total_return"] - risk_free_rate) / portfolio_vol
                if portfolio_vol > 0
                else 0
            )
            benchmark_sharpe = (
                (standard_attribution["benchmark_return"] - risk_free_rate)
                / benchmark_vol
                if benchmark_vol > 0
                else 0
            )

            # Risk-adjusted attribution
            risk_adjusted_active = portfolio_sharpe - benchmark_sharpe

            return {
                "standard_attribution": standard_attribution,
                "risk_metrics": {
                    "portfolio_volatility": float(portfolio_vol),
                    "benchmark_volatility": float(benchmark_vol),
                    "portfolio_sharpe_ratio": float(portfolio_sharpe),
                    "benchmark_sharpe_ratio": float(benchmark_sharpe),
                    "active_sharpe_ratio": float(risk_adjusted_active),
                },
                "risk_adjusted_effects": {
                    "volatility_adjusted_allocation": (
                        standard_attribution["allocation_effect"] / portfolio_vol
                        if portfolio_vol > 0
                        else 0
                    ),
                    "volatility_adjusted_selection": (
                        standard_attribution["selection_effect"] / portfolio_vol
                        if portfolio_vol > 0
                        else 0
                    ),
                },
            }

        except Exception as e:
            logger.error(f"Error calculating risk-adjusted attribution: {e}")
            raise ServiceError(f"Error calculating risk-adjusted attribution: {str(e)}")
